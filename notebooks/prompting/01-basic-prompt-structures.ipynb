{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic Prompt Structures Tutorial\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial explores two essential prompt structures used in AI interactions:\n",
        "1. Single-turn prompts\n",
        "2. Multi-turn prompts (conversations)\n",
        "\n",
        "We'll utilize Google's Gemini via OpenRouter and LangChain to illustrate these concepts.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Grasping various prompt structures is essential for effective AI communication. Single-turn prompts excel in quick, direct queries, while multi-turn prompts facilitate more nuanced, context-rich exchanges. Proficiency in these structures enhances the versatility and efficacy of AI applications across diverse scenarios.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. **Single-turn Prompts**: One-time interactions with the AI model.\n",
        "2. **Multi-turn Prompts**: Sequential exchanges that preserve context.\n",
        "3. **Prompt Templates**: Standardized structures for consistent AI querying.\n",
        "4. **Conversation Chains**: Techniques for maintaining context across multiple interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import getenv\n",
        "from typing import List\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
        "    openai_api_base=getenv(\"OPENROUTER_BASE_URL\"),\n",
        "    model_name=\"google/gemini-flash-1.5\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Single-turn Prompts\n",
        "\n",
        "Single-turn prompts are one-shot interactions with the language model. They consist of a single input (prompt) and generate a single output (response)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The three primary colors in additive color mixing (like with light) are **red, green, and blue**.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "single_turn_prompt = \"What are the three primary colors?\"\n",
        "print(llm.invoke(single_turn_prompt).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's use a PromptTemplate to create a more structured single-turn prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Color theory is a set of guiding principles that explains how colors mix, match, and create different effects.  It's used in art, design, and other fields to understand how colors interact and evoke specific emotions or responses.  It's based on the way the human eye perceives and interprets light.\n",
            "\n",
            "The three main components of color theory are:\n",
            "\n",
            "1. **Hue:** This refers to the pure color itself, like red, blue, green, yellow, etc.  It's the basic name we give to a color.\n",
            "\n",
            "2. **Saturation:** This describes the intensity or purity of a color.  A highly saturated color is vibrant and intense, while a less saturated color appears duller or more grayed.\n",
            "\n",
            "3. **Brightness (or Value):** This refers to the lightness or darkness of a color.  A bright color is light, while a dark color is closer to black.  It's also sometimes called \"lightness\" or \"value\".\n",
            "\n"
          ]
        }
      ],
      "source": [
        "structured_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Provide a brief explanation of {topic} and list its three main components.\",\n",
        ")\n",
        "\n",
        "chain = structured_prompt | llm\n",
        "print(chain.invoke({\"topic\": \"color theory\"}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can learn more about LangChain Expression Language from [LCEL](https://python.langchain.com/docs/concepts/lcel/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Multi-turn Prompts (Conversations)\n",
        "\n",
        "Multi-turn prompts involve a series of interactions with the language model, allowing for more complex and context-aware conversations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
        "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
        "\n",
        "    messages: List[BaseMessage] = Field(default_factory=list)\n",
        "\n",
        "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
        "        \"\"\"Add a list of messages to the store\"\"\"\n",
        "        self.messages.extend(messages)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "\n",
        "\n",
        "# Here we use a global variable to store the chat message history.\n",
        "# This will make it easier to inspect it to see the underlying results.\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryHistory()\n",
        "    return store[session_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's explore the fascinating world of planets!  Planets are celestial bodies that orbit a star.  They're massive enough for their own gravity to pull them into a nearly round shape, and they've cleared the neighborhood around their orbit of other objects of comparable size.  This last point is crucial \u2013 it's what distinguishes planets from dwarf planets like Pluto.\n",
            "\n",
            "We can categorize planets in a few different ways:\n",
            "\n",
            "* **By location in our solar system:** This is the most common way we talk about planets.  We have the inner, rocky planets (Mercury, Venus, Earth, and Mars) and the outer, gas giants (Jupiter, Saturn, Uranus, and Neptune).\n",
            "\n",
            "* **By composition:**\n",
            "    * **Terrestrial planets (rocky planets):** These are primarily composed of rock and metal.  They're generally smaller and denser than gas giants. Mercury, Venus, Earth, and Mars fall into this category.\n",
            "    * **Gas giants (Jovian planets):** These are massive planets composed mostly of hydrogen and helium, with smaller amounts of other gases and possibly a rocky core. Jupiter, Saturn, Uranus, and Neptune are gas giants.\n",
            "    * **Ice giants:**  A subcategory of gas giants, ice giants like Uranus and Neptune have a significant portion of their mass composed of \"ices\" \u2013 water, methane, and ammonia.\n",
            "\n",
            "* **By size:** Planets vary dramatically in size. Jupiter, the largest planet in our solar system, is over 1,000 times the volume of Earth.\n",
            "\n",
            "* **By presence of moons:** Many planets have moons (natural satellites) orbiting them.  Jupiter, for example, has dozens of moons.\n",
            "\n",
            "* **By presence of rings:**  Some planets, most notably Saturn, have extensive ring systems composed of ice, rock, and dust.  While Saturn's rings are the most prominent, Jupiter, Uranus, and Neptune also have ring systems, though they are much fainter.\n",
            "\n",
            "\n",
            "**Key differences between inner and outer planets:**\n",
            "\n",
            "| Feature        | Inner Planets (Terrestrial) | Outer Planets (Gas Giants) |\n",
            "|----------------|-----------------------------|-----------------------------|\n",
            "| **Composition** | Rock, metal                 | Hydrogen, helium, ices      |\n",
            "| **Density**     | High                         | Low                          |\n",
            "| **Size**        | Relatively small             | Very large                   |\n",
            "| **Atmosphere**  | Thin (or none, in Mercury's case) | Thick, extensive atmospheres |\n",
            "| **Moons**       | Few                          | Many                         |\n",
            "| **Rings**       | None (generally)             | Many (though varying in prominence) |\n",
            "\n",
            "\n",
            "This is just a basic overview.  Each planet has unique characteristics and fascinating features worthy of individual study.  Do you have any specific questions about a particular planet or aspect of planetary science?  I'd be happy to delve deeper!\n",
            "\n",
            "Jupiter is the largest planet in our solar system.\n",
            "\n",
            "Jupiter is vastly larger than Earth.  To give you a sense of scale:\n",
            "\n",
            "* **Volume:** Jupiter's volume is about 1,321 times greater than Earth's.  That means you could fit over 1,300 Earths inside Jupiter.\n",
            "\n",
            "* **Mass:** Jupiter's mass is about 318 times greater than Earth's.  It's so massive that it accounts for more than two-thirds of the total mass of all the planets in our solar system combined.\n",
            "\n",
            "* **Diameter:** Jupiter's diameter is about 11 times larger than Earth's.\n",
            "\n",
            "It's difficult to truly grasp these numbers, but the point is that Jupiter is an absolute giant compared to our home planet.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "conversation = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_by_session_id,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "print(\n",
        "    conversation.invoke(\n",
        "        input={\n",
        "            \"question\": \"Hi, I'm learning about space. Can you tell me about planets?\"\n",
        "        },\n",
        "        config={\"configurable\": {\"session_id\": \"foo\"}},\n",
        "    ).content\n",
        ")\n",
        "print(\n",
        "    conversation.invoke(\n",
        "        input={\"question\": \"What's the largest planet in our solar system?\"},\n",
        "        config={\"configurable\": {\"session_id\": \"foo\"}},\n",
        "    ).content\n",
        ")\n",
        "print(\n",
        "    conversation.invoke(\n",
        "        input={\"question\": \"How does its size compare to Earth?\"},\n",
        "        config={\"configurable\": {\"session_id\": \"foo\"}},\n",
        "    ).content\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare how single-turn and multi-turn prompts handle a series of related questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single-turn responses:\n",
            "Q: What is the capital of France?\n",
            "A: Paris\n",
            "\n",
            "\n",
            "Q: What is its population?\n",
            "A: Please specify what \"it\" refers to.  I need to know the country, city, region, or other entity you're asking about to tell you its population.\n",
            "\n",
            "\n",
            "Q: What is the city's most famous landmark?\n",
            "A: Please specify which city you are asking about.\n",
            "\n",
            "\n",
            "Multi-turn responses:\n",
            "Q: What is the capital of France?\n",
            "A: Paris\n",
            "\n",
            "\n",
            "Q: What is its population?\n",
            "A: The population of Paris is a bit tricky to define precisely because it depends on what area you're considering.\n",
            "\n",
            "* **Paris proper (intra-muros):**  Around 2.1 million people.  This refers to the city limits within the historical walls.\n",
            "\n",
            "* **Greater Paris (\u00cele-de-France region):**  Over 12 million people. This includes the suburbs and surrounding areas.\n",
            "\n",
            "So, the answer depends on the context.  For the city itself, it's around **2.1 million**.  For the metropolitan area, it's over **12 million**.\n",
            "\n",
            "\n",
            "Q: What is the city's most famous landmark?\n",
            "A: The Eiffel Tower\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Single-turn prompts\n",
        "prompts = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is its population?\",\n",
        "    \"What is the city's most famous landmark?\",\n",
        "]\n",
        "\n",
        "print(\"Single-turn responses:\")\n",
        "for prompt in prompts:\n",
        "    print(f\"Q: {prompt}\")\n",
        "    print(f\"A: {llm.invoke(prompt).content}\\n\")\n",
        "\n",
        "# Multi-turn prompts\n",
        "print(\"Multi-turn responses:\")\n",
        "for prompt in prompts:\n",
        "    print(f\"Q: {prompt}\")\n",
        "    response = conversation.invoke(\n",
        "        input={\"question\": prompt}, config={\"configurable\": {\"session_id\": \"bar\"}}\n",
        "    ).content\n",
        "    print(f\"A: {response}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
