{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating Prompt Effectiveness\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial delves into strategies and methodologies for assessing the efficacy of prompts used in AI language models. We'll examine a range of metrics for quantifying prompt performance and explore both hands-on and automated evaluation approaches.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "With prompt engineering playing an increasingly vital role in AI applications, it's crucial to develop robust methods for gauging prompt effectiveness. This empowers developers and researchers to fine-tune their prompts, resulting in enhanced AI model performance and more dependable outputs.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. Quantitative metrics for assessing prompt performance.\n",
        "2. Hands-on evaluation methodologies.\n",
        "3. Automated assessment techniques.\n",
        "4. Real-world examples utilizing Google's Gemini via OpenRouter and LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tangquocthai/Works/personal/vn-ds/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from os import getenv\n",
        "\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
        "    openai_api_base=getenv(\"OPENROUTER_BASE_URL\"),\n",
        "    model_name=\"google/gemini-flash-1.5\",\n",
        ")\n",
        "\n",
        "# Initialize sentence transformer for semantic similarity\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "def semantic_similarity(text1, text2):\n",
        "    \"\"\"Calculate semantic similarity between two texts using cosine similarity.\"\"\"\n",
        "    embeddings = sentence_model.encode([text1, text2])\n",
        "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics for Measuring Prompt Performance\n",
        "\n",
        "Let's define some key metrics for evaluating prompt effectiveness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relevance_score(response, expected_content):\n",
        "    \"\"\"Calculate relevance score based on semantic similarity to expected content.\"\"\"\n",
        "    return semantic_similarity(response, expected_content)\n",
        "\n",
        "\n",
        "def consistency_score(responses):\n",
        "    \"\"\"Calculate consistency score based on similarity between multiple responses.\"\"\"\n",
        "    if len(responses) < 2:\n",
        "        return 1.0  # Perfect consistency if there's only one response\n",
        "    similarities = []\n",
        "    for i in range(len(responses)):\n",
        "        for j in range(i + 1, len(responses)):\n",
        "            similarities.append(semantic_similarity(responses[i], responses[j]))\n",
        "    return np.mean(similarities)\n",
        "\n",
        "\n",
        "def specificity_score(response):\n",
        "    \"\"\"Calculate specificity score based on response length and unique word count.\"\"\"\n",
        "    words = response.split()\n",
        "    unique_words = set(words)\n",
        "    return len(unique_words) / len(words) if words else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manual Evaluation Techniques\n",
        "\n",
        "Manual evaluation involves human assessment of prompt-response pairs. Let's create a function to simulate this process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Explain the concept of machine learning in simple terms.\n",
            "Response: Imagine you have a puppy you're trying to teach to sit.  Instead of explicitly telling it every step (\"First, put your butt down... now hold it... good dog!\"), you show it what \"sit\" means many times, rewarding it when it gets close and correcting it when it's wrong.  Eventually, the puppy learns to sit on command without you needing to explain it every time.\n",
            "\n",
            "Machine learning is similar.  Instead of programming a computer with specific rules for every situation, you give it lots of examples (data) and let it figure out the rules itself.  The more examples it sees, the better it gets at recognizing patterns and making predictions.\n",
            "\n",
            "So, instead of a puppy, it's a computer program; instead of treats and corrections, it's algorithms and data; and instead of \"sit\", it's anything from recognizing cats in photos to predicting the stock market.  The computer learns from the data, improving its performance over time without being explicitly programmed for each task.\n",
            "\n",
            "\n",
            "Evaluation Criteria:\n",
            "Clarity: 0.0/10\n",
            "Accuracy: 1.0/10\n",
            "Simplicity: 1.0/10\n",
            "\n",
            "Additional Comments:\n",
            "Comments: 1\n"
          ]
        }
      ],
      "source": [
        "def manual_evaluation(prompt, response, criteria):\n",
        "    \"\"\"Simulate manual evaluation of a prompt-response pair.\"\"\"\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(\"\\nEvaluation Criteria:\")\n",
        "    for criterion in criteria:\n",
        "        score = float(input(f\"Score for {criterion} (0-10): \"))\n",
        "        print(f\"{criterion}: {score}/10\")\n",
        "    print(\"\\nAdditional Comments:\")\n",
        "    comments = input(\"Enter any additional comments: \")\n",
        "    print(f\"Comments: {comments}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Explain the concept of machine learning in simple terms.\"\n",
        "response = llm.invoke(prompt).content\n",
        "criteria = [\"Clarity\", \"Accuracy\", \"Simplicity\"]\n",
        "manual_evaluation(prompt, response, criteria)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Automated Evaluation Techniques\n",
        "\n",
        "Now, let's implement some automated evaluation techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What are the three main types of machine learning?\n",
            "Response: The three main types of machine learning are:\n",
            "\n",
            "1. **Supervised Learning:**  The algorithm learns from a labeled dataset, meaning the data includes both input features and the corresponding desired output (target variable).  The algorithm learns to map inputs to outputs based on this labeled data. Examples include image classification (input: image, output: object label) and spam detection (input: email, output: spam/not spam).\n",
            "\n",
            "2. **Unsupervised Learning:** The algorithm learns from an unlabeled dataset, meaning only input features are provided, and there's no corresponding target variable. The algorithm aims to discover patterns, structures, or relationships within the data. Examples include clustering (grouping similar data points together) and dimensionality reduction (reducing the number of variables while preserving important information).\n",
            "\n",
            "3. **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment. It receives rewards or penalties based on its actions and learns to choose actions that maximize cumulative rewards over time. Examples include game playing (e.g., AlphaGo), robotics, and resource management.\n",
            "\n",
            "\n",
            "Relevance Score: 0.81\n",
            "Specificity Score: 0.70\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'relevance': 0.8075807, 'specificity': 0.6956521739130435}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def automated_evaluation(prompt, response, expected_content):\n",
        "    \"\"\"Perform automated evaluation of a prompt-response pair.\"\"\"\n",
        "    relevance = relevance_score(response, expected_content)\n",
        "    specificity = specificity_score(response)\n",
        "\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"\\nRelevance Score: {relevance:.2f}\")\n",
        "    print(f\"Specificity Score: {specificity:.2f}\")\n",
        "\n",
        "    return {\"relevance\": relevance, \"specificity\": specificity}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"What are the three main types of machine learning?\"\n",
        "expected_content = \"The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
        "response = llm.invoke(prompt).content\n",
        "automated_evaluation(prompt, response, expected_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparative Analysis\n",
        "\n",
        "Let's compare the effectiveness of different prompts for the same task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: List the types of machine learning.\n",
            "Response: Machine learning can be broadly categorized in several ways, and these categories often overlap.  Here are some common types:\n",
            "\n",
            "**Based on Learning Style:**\n",
            "\n",
            "* **Supervised Learning:**  The algorithm learns from a labeled dataset, where each data point is tagged with the correct answer.  The goal is to learn a mapping from inputs to outputs.  Examples include:\n",
            "    * **Regression:** Predicting a continuous output (e.g., house price prediction).\n",
            "    * **Classification:** Predicting a categorical output (e.g., spam detection).\n",
            "\n",
            "* **Unsupervised Learning:** The algorithm learns from an unlabeled dataset, identifying patterns and structures without explicit guidance. Examples include:\n",
            "    * **Clustering:** Grouping similar data points together (e.g., customer segmentation).\n",
            "    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., principal component analysis).\n",
            "    * **Association Rule Learning:** Discovering relationships between variables (e.g., market basket analysis).\n",
            "\n",
            "* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards or penalties based on its actions, aiming to maximize cumulative reward. Examples include:\n",
            "    * **Game playing:** Training AI agents to play games like chess or Go.\n",
            "    * **Robotics:** Controlling robots to perform tasks in complex environments.\n",
            "\n",
            "\n",
            "**Based on other characteristics:**\n",
            "\n",
            "* **Batch Learning:** The algorithm learns from the entire dataset at once.\n",
            "* **Online Learning:** The algorithm learns incrementally from individual data points or small batches.\n",
            "* **Semi-supervised Learning:** The algorithm learns from a dataset containing both labeled and unlabeled data.\n",
            "* **Self-supervised Learning:** The algorithm learns from unlabeled data by creating its own labels or tasks.  (A sub-type of unsupervised learning)\n",
            "* **Transfer Learning:**  Leveraging knowledge gained from solving one problem to improve performance on a related problem.\n",
            "* **Active Learning:** The algorithm selectively queries the user for labels on specific data points.\n",
            "\n",
            "\n",
            "It's important to note that these categories are not mutually exclusive.  For example, a system might use a combination of supervised and unsupervised learning techniques.  The best approach depends on the specific problem and available data.\n",
            "\n",
            "\n",
            "Relevance Score: 0.70\n",
            "Specificity Score: 0.61\n",
            "Prompt: What are the main categories of machine learning algorithms?\n",
            "Response: Machine learning algorithms are broadly categorized into several main types, though the lines between them can sometimes blur.  The most common categorizations are:\n",
            "\n",
            "* **Supervised Learning:**  Algorithms learn from labeled data, where each data point is tagged with the correct answer. The goal is to learn a mapping from inputs to outputs.  This category includes:\n",
            "\n",
            "    * **Regression:** Predicts a continuous output variable. Examples include linear regression, polynomial regression, support vector regression, and decision tree regression.\n",
            "    * **Classification:** Predicts a categorical output variable. Examples include logistic regression, support vector machines (SVMs), decision trees, naive Bayes, k-nearest neighbors (k-NN), and random forests.\n",
            "\n",
            "* **Unsupervised Learning:** Algorithms learn from unlabeled data, where no correct answers are provided. The goal is to discover patterns, structures, or relationships within the data. This category includes:\n",
            "\n",
            "    * **Clustering:** Groups similar data points together. Examples include k-means clustering, hierarchical clustering, and DBSCAN.\n",
            "    * **Dimensionality Reduction:** Reduces the number of variables while preserving important information. Examples include principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), and linear discriminant analysis (LDA).\n",
            "    * **Association Rule Learning:** Discovers relationships between variables in large datasets.  A common example is the Apriori algorithm used in market basket analysis.\n",
            "\n",
            "* **Reinforcement Learning:** Algorithms learn through trial and error by interacting with an environment. The algorithm receives rewards or penalties based on its actions, and learns to maximize its cumulative reward. Examples include Q-learning and Deep Q-Networks (DQNs).\n",
            "\n",
            "\n",
            "* **Semi-Supervised Learning:**  Algorithms learn from a combination of labeled and unlabeled data. This is often used when labeled data is scarce or expensive to obtain.\n",
            "\n",
            "\n",
            "* **Self-Supervised Learning:**  Algorithms learn from unlabeled data by creating their own \"pseudo-labels\" or tasks.  This is a rapidly developing area, often leveraging techniques like contrastive learning or pretext tasks.\n",
            "\n",
            "\n",
            "It's important to note that some algorithms can be adapted or used for multiple categories. For example, a decision tree can be used for both regression and classification.  The choice of algorithm depends heavily on the specific problem, the nature of the data, and the desired outcome.\n",
            "\n",
            "\n",
            "Relevance Score: 0.67\n",
            "Specificity Score: 0.60\n",
            "Prompt: Explain the different approaches to machine learning.\n",
            "Response: Machine learning approaches are broadly categorized into several types, primarily based on how they learn from data:\n",
            "\n",
            "**1. Supervised Learning:**\n",
            "\n",
            "* **Definition:** This approach uses labeled datasets, meaning each data point is tagged with the correct answer or outcome. The algorithm learns to map inputs to outputs based on these labeled examples.  The goal is to learn a function that can accurately predict the output for new, unseen inputs.\n",
            "* **Types:**\n",
            "    * **Regression:** Predicts a continuous output variable (e.g., predicting house prices, stock prices). Examples include Linear Regression, Support Vector Regression, Decision Tree Regression.\n",
            "    * **Classification:** Predicts a categorical output variable (e.g., classifying emails as spam or not spam, identifying images of cats or dogs). Examples include Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Naive Bayes, K-Nearest Neighbors.\n",
            "* **Example:** Training a model to identify handwritten digits by showing it thousands of images of digits (0-9) with their corresponding labels.\n",
            "\n",
            "**2. Unsupervised Learning:**\n",
            "\n",
            "* **Definition:** This approach uses unlabeled datasets, meaning the data points have no associated answers or outcomes. The algorithm learns to identify patterns, structures, and relationships within the data without explicit guidance.\n",
            "* **Types:**\n",
            "    * **Clustering:** Groups similar data points together into clusters (e.g., customer segmentation, anomaly detection). Examples include K-Means clustering, Hierarchical clustering, DBSCAN.\n",
            "    * **Dimensionality Reduction:** Reduces the number of variables while preserving important information (e.g., feature extraction, data visualization). Examples include Principal Component Analysis (PCA), t-distributed Stochastic Neighbor Embedding (t-SNE).\n",
            "    * **Association Rule Learning:** Discovers relationships between variables in large datasets (e.g., market basket analysis \u2013 finding products frequently bought together). Example: Apriori algorithm.\n",
            "* **Example:** Grouping customers based on their purchasing behavior without knowing their demographics beforehand.\n",
            "\n",
            "**3. Reinforcement Learning:**\n",
            "\n",
            "* **Definition:** This approach involves an agent that learns to interact with an environment by taking actions and receiving rewards or penalties. The agent learns a policy that maximizes its cumulative reward over time.\n",
            "* **Types:**\n",
            "    * **Model-based RL:** The agent builds a model of the environment to predict the outcomes of its actions.\n",
            "    * **Model-free RL:** The agent learns directly from experience without explicitly modeling the environment.  Examples include Q-learning, SARSA.\n",
            "* **Example:** Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
            "\n",
            "\n",
            "**4. Semi-Supervised Learning:**\n",
            "\n",
            "* **Definition:** This approach uses a combination of labeled and unlabeled data.  It leverages the information from both to improve learning accuracy, particularly useful when labeled data is scarce and expensive to obtain.\n",
            "* **Example:** Training a model to classify images using a small set of labeled images and a large set of unlabeled images.\n",
            "\n",
            "\n",
            "**5. Self-Supervised Learning:**\n",
            "\n",
            "* **Definition:**  This approach creates pseudo-labels from the unlabeled data itself. The model learns to predict these created labels, indirectly learning useful representations from the data. This is different from unsupervised learning because it uses a pretext task to learn representations, generating supervision from the data itself.\n",
            "* **Example:** Training a model to predict masked words in a sentence, learning contextual word embeddings in the process.\n",
            "\n",
            "\n",
            "**6. Transfer Learning:**\n",
            "\n",
            "* **Definition:** This approach involves leveraging knowledge learned from one task to improve performance on a related task.  It's useful when data for the target task is limited.\n",
            "* **Example:** Using a model pre-trained on a massive dataset of images (like ImageNet) to then fine-tune it for a specific image classification task with a smaller dataset.\n",
            "\n",
            "\n",
            "These approaches are not mutually exclusive; combinations are often used to solve complex problems.  The choice of approach depends on the nature of the data, the problem being solved, and the available resources.\n",
            "\n",
            "\n",
            "Relevance Score: 0.69\n",
            "Specificity Score: 0.54\n",
            "Prompt Comparison Results:\n",
            "\n",
            "1. Prompt: List the types of machine learning.\n",
            "   Relevance: 0.70\n",
            "   Specificity: 0.61\n",
            "\n",
            "2. Prompt: Explain the different approaches to machine learning.\n",
            "   Relevance: 0.69\n",
            "   Specificity: 0.54\n",
            "\n",
            "3. Prompt: What are the main categories of machine learning algorithms?\n",
            "   Relevance: 0.67\n",
            "   Specificity: 0.60\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'prompt': 'List the types of machine learning.',\n",
              "  'relevance': 0.6978776,\n",
              "  'specificity': 0.6125},\n",
              " {'prompt': 'Explain the different approaches to machine learning.',\n",
              "  'relevance': 0.68783927,\n",
              "  'specificity': 0.5397631133671743},\n",
              " {'prompt': 'What are the main categories of machine learning algorithms?',\n",
              "  'relevance': 0.6737312,\n",
              "  'specificity': 0.5952380952380952}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compare_prompts(prompts, expected_content):\n",
        "    \"\"\"Compare the effectiveness of multiple prompts for the same task.\"\"\"\n",
        "    results = []\n",
        "    for prompt in prompts:\n",
        "        response = llm.invoke(prompt).content\n",
        "        evaluation = automated_evaluation(prompt, response, expected_content)\n",
        "        results.append({\"prompt\": prompt, **evaluation})\n",
        "\n",
        "    # Sort results by relevance score\n",
        "    sorted_results = sorted(results, key=lambda x: x[\"relevance\"], reverse=True)\n",
        "\n",
        "    print(\"Prompt Comparison Results:\")\n",
        "    for i, result in enumerate(sorted_results, 1):\n",
        "        print(f\"\\n{i}. Prompt: {result['prompt']}\")\n",
        "        print(f\"   Relevance: {result['relevance']:.2f}\")\n",
        "        print(f\"   Specificity: {result['specificity']:.2f}\")\n",
        "\n",
        "    return sorted_results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompts = [\n",
        "    \"List the types of machine learning.\",\n",
        "    \"What are the main categories of machine learning algorithms?\",\n",
        "    \"Explain the different approaches to machine learning.\",\n",
        "]\n",
        "expected_content = \"The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
        "compare_prompts(prompts, expected_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Putting It All Together\n",
        "\n",
        "Now, let's create a comprehensive prompt evaluation function that combines both manual and automated techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automated Evaluation:\n",
            "Prompt: Explain the concept of overfitting in machine learning.\n",
            "Response: Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data (which is the goal), it memorizes the specific details and noise of the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\n",
            "\n",
            "Imagine you're teaching a child to identify cats.  If you only show them pictures of fluffy Persian cats, they might learn to identify only fluffy Persian cats as \"cat.\"  They've overfit to the specific examples shown, failing to generalize to other breeds like Siamese cats or even short-haired cats.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "* **High training accuracy, low testing accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has already seen but struggles when presented with new, similar data.\n",
            "\n",
            "* **Complex model:** Overfitting often happens with models that have high complexity (e.g., many parameters, deep neural networks with many layers).  These complex models have the capacity to capture even minute details in the training data, including noise, leading to memorization instead of generalization.\n",
            "\n",
            "* **Noise sensitivity:** Overfit models are highly sensitive to noise or outliers in the training data.  They might learn patterns that are artifacts of the noise rather than true underlying relationships.\n",
            "\n",
            "* **Poor generalization:** The ultimate consequence of overfitting is poor generalization. The model fails to accurately predict or classify new, unseen data, rendering it useless in real-world applications.\n",
            "\n",
            "\n",
            "**Causes of Overfitting:**\n",
            "\n",
            "* **Insufficient data:**  A small training dataset doesn't provide enough examples to allow the model to learn the true underlying patterns without memorizing the specific instances.\n",
            "* **High model complexity:**  Models with too many parameters can easily overfit, especially when the data is limited.\n",
            "* **Noisy data:**  Errors or outliers in the training data can lead the model to learn incorrect relationships.\n",
            "\n",
            "\n",
            "**Mitigation Techniques:**\n",
            "\n",
            "* **Regularization:** Techniques like L1 and L2 regularization add penalties to the model's complexity, discouraging it from learning overly complex relationships.\n",
            "* **Cross-validation:**  Evaluating the model on multiple subsets of the training data helps assess its generalization ability and detect overfitting.\n",
            "* **Data augmentation:** Increasing the size and diversity of the training dataset reduces the influence of noise and outliers.\n",
            "* **Pruning (for decision trees):** Removing less important branches of a decision tree can reduce complexity and prevent overfitting.\n",
            "* **Dropout (for neural networks):** Randomly ignoring neurons during training prevents the network from relying too heavily on any single neuron or feature.\n",
            "* **Early stopping:** Monitoring the model's performance on a validation set during training and stopping the training process when performance starts to degrade.\n",
            "* **Feature selection/engineering:** Selecting relevant features and creating new informative features can improve the model's ability to generalize.\n",
            "\n",
            "\n",
            "Understanding and addressing overfitting is crucial for building reliable and effective machine learning models.  The goal is always to find a balance between model complexity and generalization ability, allowing the model to capture meaningful patterns without memorizing the noise in the training data.\n",
            "\n",
            "\n",
            "Relevance Score: 0.75\n",
            "Specificity Score: 0.54\n",
            "\n",
            "Manual Evaluation:\n",
            "Prompt: Explain the concept of overfitting in machine learning.\n",
            "Response: Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data (which is the goal), it memorizes the specific details and noise of the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\n",
            "\n",
            "Imagine you're teaching a child to identify cats.  If you only show them pictures of fluffy Persian cats, they might learn to identify only fluffy Persian cats as \"cat.\"  They've overfit to the specific examples shown, failing to generalize to other breeds like Siamese cats or even short-haired cats.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "* **High training accuracy, low testing accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has already seen but struggles when presented with new, similar data.\n",
            "\n",
            "* **Complex model:** Overfitting often happens with models that have high complexity (e.g., many parameters, deep neural networks with many layers).  These complex models have the capacity to capture even minute details in the training data, including noise, leading to memorization instead of generalization.\n",
            "\n",
            "* **Noise sensitivity:** Overfit models are highly sensitive to noise or outliers in the training data.  They might learn patterns that are artifacts of the noise rather than true underlying relationships.\n",
            "\n",
            "* **Poor generalization:** The ultimate consequence of overfitting is poor generalization. The model fails to accurately predict or classify new, unseen data, rendering it useless in real-world applications.\n",
            "\n",
            "\n",
            "**Causes of Overfitting:**\n",
            "\n",
            "* **Insufficient data:**  A small training dataset doesn't provide enough examples to allow the model to learn the true underlying patterns without memorizing the specific instances.\n",
            "* **High model complexity:**  Models with too many parameters can easily overfit, especially when the data is limited.\n",
            "* **Noisy data:**  Errors or outliers in the training data can lead the model to learn incorrect relationships.\n",
            "\n",
            "\n",
            "**Mitigation Techniques:**\n",
            "\n",
            "* **Regularization:** Techniques like L1 and L2 regularization add penalties to the model's complexity, discouraging it from learning overly complex relationships.\n",
            "* **Cross-validation:**  Evaluating the model on multiple subsets of the training data helps assess its generalization ability and detect overfitting.\n",
            "* **Data augmentation:** Increasing the size and diversity of the training dataset reduces the influence of noise and outliers.\n",
            "* **Pruning (for decision trees):** Removing less important branches of a decision tree can reduce complexity and prevent overfitting.\n",
            "* **Dropout (for neural networks):** Randomly ignoring neurons during training prevents the network from relying too heavily on any single neuron or feature.\n",
            "* **Early stopping:** Monitoring the model's performance on a validation set during training and stopping the training process when performance starts to degrade.\n",
            "* **Feature selection/engineering:** Selecting relevant features and creating new informative features can improve the model's ability to generalize.\n",
            "\n",
            "\n",
            "Understanding and addressing overfitting is crucial for building reliable and effective machine learning models.  The goal is always to find a balance between model complexity and generalization ability, allowing the model to capture meaningful patterns without memorizing the noise in the training data.\n",
            "\n",
            "\n",
            "Evaluation Criteria:\n",
            "Clarity: 5.0/10\n",
            "Accuracy: 3.0/10\n",
            "Relevance: 4.0/10\n",
            "\n",
            "Additional Comments:\n",
            "Comments: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Explain the concept of overfitting in machine learning.',\n",
              " 'response': 'Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data (which is the goal), it memorizes the specific details and noise of the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\\n\\nImagine you\\'re teaching a child to identify cats.  If you only show them pictures of fluffy Persian cats, they might learn to identify only fluffy Persian cats as \"cat.\"  They\\'ve overfit to the specific examples shown, failing to generalize to other breeds like Siamese cats or even short-haired cats.\\n\\nHere\\'s a breakdown of the key aspects:\\n\\n* **High training accuracy, low testing accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has already seen but struggles when presented with new, similar data.\\n\\n* **Complex model:** Overfitting often happens with models that have high complexity (e.g., many parameters, deep neural networks with many layers).  These complex models have the capacity to capture even minute details in the training data, including noise, leading to memorization instead of generalization.\\n\\n* **Noise sensitivity:** Overfit models are highly sensitive to noise or outliers in the training data.  They might learn patterns that are artifacts of the noise rather than true underlying relationships.\\n\\n* **Poor generalization:** The ultimate consequence of overfitting is poor generalization. The model fails to accurately predict or classify new, unseen data, rendering it useless in real-world applications.\\n\\n\\n**Causes of Overfitting:**\\n\\n* **Insufficient data:**  A small training dataset doesn\\'t provide enough examples to allow the model to learn the true underlying patterns without memorizing the specific instances.\\n* **High model complexity:**  Models with too many parameters can easily overfit, especially when the data is limited.\\n* **Noisy data:**  Errors or outliers in the training data can lead the model to learn incorrect relationships.\\n\\n\\n**Mitigation Techniques:**\\n\\n* **Regularization:** Techniques like L1 and L2 regularization add penalties to the model\\'s complexity, discouraging it from learning overly complex relationships.\\n* **Cross-validation:**  Evaluating the model on multiple subsets of the training data helps assess its generalization ability and detect overfitting.\\n* **Data augmentation:** Increasing the size and diversity of the training dataset reduces the influence of noise and outliers.\\n* **Pruning (for decision trees):** Removing less important branches of a decision tree can reduce complexity and prevent overfitting.\\n* **Dropout (for neural networks):** Randomly ignoring neurons during training prevents the network from relying too heavily on any single neuron or feature.\\n* **Early stopping:** Monitoring the model\\'s performance on a validation set during training and stopping the training process when performance starts to degrade.\\n* **Feature selection/engineering:** Selecting relevant features and creating new informative features can improve the model\\'s ability to generalize.\\n\\n\\nUnderstanding and addressing overfitting is crucial for building reliable and effective machine learning models.  The goal is always to find a balance between model complexity and generalization ability, allowing the model to capture meaningful patterns without memorizing the noise in the training data.\\n',\n",
              " 'relevance': 0.7535591,\n",
              " 'specificity': 0.5363457760314342}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_prompt(\n",
        "    prompt, expected_content, manual_criteria=[\"Clarity\", \"Accuracy\", \"Relevance\"]\n",
        "):\n",
        "    \"\"\"Perform a comprehensive evaluation of a prompt using both manual and automated techniques.\"\"\"\n",
        "    response = llm.invoke(prompt).content\n",
        "\n",
        "    print(\"Automated Evaluation:\")\n",
        "    auto_results = automated_evaluation(prompt, response, expected_content)\n",
        "\n",
        "    print(\"\\nManual Evaluation:\")\n",
        "    manual_evaluation(prompt, response, manual_criteria)\n",
        "\n",
        "    return {\"prompt\": prompt, \"response\": response, **auto_results}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Explain the concept of overfitting in machine learning.\"\n",
        "expected_content = \"Overfitting occurs when a model learns the training data too well, including its noise and fluctuations, leading to poor generalization on new, unseen data.\"\n",
        "evaluate_prompt(prompt, expected_content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
